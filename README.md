# Machine Learning
## Decision Tree
In the notebook, In part B, I implemented the Decision Tree Algorithm and changed Hyperparameters such as ```Max Depth``` and ```Min Samples Leaf```:
<details>
  <summary>Max Depth</summary>
   It Determines the maximum depth or level of the tree. It controls the number of splits or decision nodes in the tree.
</details>
<details>
  <summary>Min Samples Leaf</summary>
   It specifies the minimum number of samples required to be at a leaf node. 
   A leaf node is a node that does not split further and represents a final decision or prediction.
</details>

In each situation, I have changed ```Learning Rate``` and plotted it to find the best number of the Hyperparameters.<br>
In part C, I trained data using ``` RANDOM FOREST``` and ```Gradient Boosting```. Finally, plotted the Learning Curve for each one.
> Between these three algorithms, ***Random Forest*** and ***Gradient Boosting*** have higher Test Score
<br>
Also, you can find the Dataset as a numpy file and use it for your project.


